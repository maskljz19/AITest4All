# AI测试用例生成系统 - 用户指南

## 目录

- [系统概述](#系统概述)
- [快速入门](#快速入门)
- [功能详解](#功能详解)
- [最佳实践](#最佳实践)
- [常见问题](#常见问题)

## 系统概述

AI测试用例生成系统是一个智能化的测试用例设计工具，通过AI技术帮助测试工程师快速生成高质量的测试用例。系统采用多Agent协作架构，支持UI测试、接口测试和白盒测试等多种测试类型。

### 核心优势

- **智能化**: 基于大语言模型，自动理解需求并生成用例
- **标准化**: 统一的用例格式和质量标准
- **高效率**: 大幅缩短用例编写时间
- **可定制**: 支持自定义模板、脚本和提示词
- **交互式**: 多轮对话优化，逐步完善用例

## 快速入门

### 第一步：登录系统

1. 打开浏览器，访问系统地址（默认：http://localhost:5173）
2. 使用管理员提供的账号密码登录

### 第二步：创建第一个测试用例

1. 点击左侧菜单"用例生成"
2. 选择测试类型（UI测试/接口测试/白盒测试）
3. 输入需求描述或上传需求文档
4. 点击"开始生成"按钮
5. 等待AI分析需求并生成用例
6. 查看生成的用例，进行必要的调整
7. 导出用例文件

### 第三步：优化用例

1. 选中需要优化的用例
2. 在对话框中输入优化指令，如"使这些用例更详细"
3. AI会根据指令重新生成优化后的用例
4. 重复此过程直到满意

## 功能详解

### 1. 需求分析

#### 1.1 输入需求

系统支持多种需求输入方式：

**方式一：上传文档**
- 支持格式：Word (.docx)、PDF (.pdf)、Markdown (.md)
- 文件大小限制：10MB
- 操作步骤：
  1. 点击"上传文档"标签
  2. 拖拽文件到上传区域或点击选择文件
  3. 等待文件上传完成

**方式二：输入URL**
- 支持在线文档链接（语雀、Confluence、Google Docs等）
- 操作步骤：
  1. 点击"输入URL"标签
  2. 在输入框中粘贴文档链接
  3. 点击"加载"按钮

**方式三：手动输入**
- 直接在富文本编辑器中输入需求描述
- 支持Markdown格式
- 操作步骤：
  1. 点击"手动输入"标签
  2. 在编辑器中输入或粘贴需求文本
  3. 使用工具栏格式化文本

#### 1.2 选择测试类型

根据需求特点选择合适的测试类型：

- **UI测试**: 适用于Web应用界面测试
- **接口测试**: 适用于RESTful API测试
- **白盒测试**: 适用于单元测试和代码逻辑测试

#### 1.3 关联知识库

选择相关的知识库文档辅助分析：

- **历史用例库**: 参考类似功能的历史用例
- **缺陷库**: 识别高风险场景
- **业务规则库**: 理解业务逻辑
- **接口文档库**: 获取接口定义

#### 1.4 查看分析结果

AI分析完成后，会展示以下内容：

- **功能点列表**: 需要测试的所有功能点
- **业务规则**: 关键的业务规则和约束
- **数据模型**: 涉及的数据实体和字段
- **接口定义**: API端点和参数（接口测试）
- **测试重点**: 需要重点关注的部分
- **风险点**: 潜在的风险和边界情况

您可以：
- 直接确认进入下一步
- 在线编辑修改分析结果
- 调整Agent配置重新分析

### 2. 场景生成

#### 2.1 自动生成场景

基于需求分析结果，AI会自动生成多种测试场景：

- **正常场景**: 用户正常操作流程
- **异常场景**: 错误输入、网络异常、权限不足等
- **边界场景**: 最大值、最小值、空值、特殊字符等
- **性能场景**: 并发、大数据量（可选）
- **安全场景**: 认证、授权、注入攻击（可选）

#### 2.2 场景管理

对生成的场景进行管理：

**选择场景**
- 勾选需要的场景
- 使用"全选"/"反选"快速操作
- 按优先级筛选场景

**删除场景**
- 点击场景卡片上的删除按钮
- 或选中后批量删除

**补充场景**
- 点击"补充场景"按钮
- 在对话框中描述需要补充的场景
- 例如："补充登录失败的场景"

#### 2.3 场景详情

点击场景卡片查看详细信息：

- 场景名称
- 场景描述
- 前置条件
- 预期结果
- 优先级（P0/P1/P2/P3）
- 场景类型（正常/异常/边界等）

### 3. 用例生成

#### 3.1 自动生成用例

AI会为每个选中的场景生成详细的测试用例：

**UI测试用例包含**：
- 用例ID和标题
- 测试类型和优先级
- 前置条件
- 详细的操作步骤（具体到点击哪个按钮、输入什么内容）
- 每个步骤的预期结果
- 测试数据
- 后置条件

**接口测试用例包含**：
- 用例ID和标题
- 请求方法和URL
- 请求头和请求体
- 断言配置（状态码、响应体、响应时间）
- 前置脚本和后置脚本
- 测试数据

**白盒测试用例包含**：
- 测试函数名
- 测试目标（函数/方法）
- Mock配置
- 输入参数
- 预期输出
- 断言语句

#### 3.2 用例列表操作

**查看用例**
- 用例以表格形式展示
- 点击用例行展开查看详情
- 支持按优先级、类型筛选

**选择用例**
- 勾选需要的用例
- 使用"全选"/"反选"快速操作
- 支持搜索后选择

**编辑用例**
- 点击"编辑"按钮
- 在弹出的编辑器中修改用例内容
- 支持修改标题、步骤、数据等所有字段
- 点击"保存"确认修改

**删除用例**
- 点击"删除"按钮删除单个用例
- 或选中后批量删除

#### 3.3 交互式优化

通过对话方式优化用例：

**优化指令示例**：
- "优化选中的用例，使其更详细"
- "简化这些用例，去掉冗余步骤"
- "为选中的用例添加异常场景"
- "检查这些用例是否符合SMART原则"

**补充指令示例**：
- "补充登录失败的场景"
- "增加性能测试用例"
- "添加安全测试场景"
- "补充边界值测试"

**重新生成指令示例**：
- "重新生成选中的用例"
- "用不同的方式生成这些用例"
- "参考模板重新生成"

**分析指令示例**：
- "分析当前用例的覆盖度"
- "检查是否有重复用例"
- "评估用例质量"

#### 3.4 使用模板

应用预定义的用例模板：

1. 点击"应用模板"按钮
2. 选择合适的模板
3. AI会按照模板格式生成用例
4. 可以在设置中管理自定义模板

#### 3.5 使用脚本

使用Python脚本生成测试数据：

1. 在用例编辑器中，数据字段使用脚本标记
2. 例如：`{{script:generate_phone_number}}`
3. 系统会自动执行脚本并替换为生成的数据
4. 可以在"脚本管理"中查看和编辑脚本

### 4. 代码生成（可选）

#### 4.1 选择是否生成代码

在用例生成完成后，可以选择生成自动化测试代码：

1. 打开"代码生成"开关
2. 选择技术栈（或使用默认配置）
3. 点击"生成代码"按钮

#### 4.2 技术栈配置

**默认技术栈**：

- **UI测试**: Pytest + Selenium + Page Object Model
- **接口测试**: Pytest + Requests
- **白盒测试**: Pytest + Mock

**自定义技术栈**：

在输入框中描述您的技术栈，例如：
- "使用Pytest和Appium进行移动端测试"
- "使用Jest和Supertest进行Node.js接口测试"

#### 4.3 代码预览和编辑

生成的代码会在Monaco编辑器中展示：

- 左侧显示文件树
- 右侧显示代码内容
- 支持语法高亮和代码折叠
- 可以在线编辑代码
- 点击文件名切换查看不同文件

#### 4.4 代码文件说明

生成的代码包含：

- **测试用例文件**: test_*.py
- **页面对象文件**: page_objects/*.py（UI测试）
- **API客户端文件**: api_client.py（接口测试）
- **配置文件**: conftest.py、pytest.ini
- **依赖文件**: requirements.txt
- **说明文档**: README.md

### 5. 质量优化

#### 5.1 质量分析

AI会从多个维度分析用例质量：

**需求覆盖度分析**：
- 计算覆盖百分比
- 列出未覆盖的功能点
- 列出缺失的重要场景

**用例质量分析**：
- 识别重复或冗余的用例
- 识别不符合SMART原则的用例
- 识别测试数据不完整的用例
- 识别断言不充分的用例

**场景完整性分析**：
- 正常场景是否完整
- 异常场景是否充分
- 边界场景是否覆盖
- 是否考虑了并发、性能、安全

#### 5.2 质量报告

查看详细的质量报告：

- **覆盖度图表**: 可视化展示覆盖情况
- **问题列表**: 详细列出所有发现的问题
- **改进建议**: 针对每个问题的具体建议
- **质量评分**: 总分和各维度得分

#### 5.3 根据建议优化

根据质量报告优化用例：

**自动优化**：
- 点击"自动优化"按钮
- AI会根据建议自动调整用例

**手动优化**：
- 点击"返回编辑"按钮
- 返回用例列表手动修改
- 参考建议进行调整

### 6. 导出用例

#### 6.1 选择导出内容

勾选需要导出的内容：

- ☑ 用例列表（已选中的用例）
- ☑ 测试场景
- ☑ 质量报告
- ☐ Agent配置
- ☑ 生成的代码（如有）

#### 6.2 选择导出格式

**用例导出格式**：

- **Excel**: 标准测试用例表格，适合导入测试管理工具
- **Word**: 详细测试用例文档，适合评审和归档
- **JSON**: 结构化数据，适合程序处理
- **Markdown**: 纯文本格式，适合版本管理
- **HTML**: 网页格式，适合在线查看和分享

**代码导出格式**：

- **ZIP压缩包**: 包含所有代码文件和目录结构
- **单文件**: 合并为单个Python文件

#### 6.3 下载文件

1. 点击"导出"按钮
2. 系统生成文件
3. 浏览器自动下载文件
4. 文件名格式：`测试用例_项目名_日期.格式`

#### 6.4 保存到数据库（可选）

如果需要保存用例到系统数据库：

1. 勾选"保存到数据库"选项
2. 选择或创建项目
3. 点击"保存"按钮
4. 用例会保存到系统中，可以后续查看和管理

### 7. 知识库管理

#### 7.1 上传文档

1. 进入"知识库管理"页面
2. 点击"上传文档"按钮
3. 选择文档类型（用例/缺陷/规则/接口）
4. 上传文件或输入URL
5. 添加标签和描述
6. 点击"确认上传"

#### 7.2 管理文档

**查看文档**：
- 文档列表展示所有已上传的文档
- 点击文档名称查看详情
- 支持在线预览

**搜索文档**：
- 使用搜索框输入关键词
- 支持按类型、标签筛选
- 支持语义搜索

**编辑文档**：
- 点击"编辑"按钮
- 修改文档信息和标签
- 更新文档内容

**删除文档**：
- 点击"删除"按钮
- 确认删除操作

#### 7.3 文档分类

使用标签对文档进行分类：

- 按项目分类：项目A、项目B
- 按模块分类：登录模块、支付模块
- 按类型分类：功能用例、性能用例
- 自定义标签

### 8. 脚本管理

#### 8.1 创建脚本

1. 进入"脚本管理"页面
2. 点击"新建脚本"按钮
3. 输入脚本名称和描述
4. 在Monaco编辑器中编写Python代码
5. 点击"测试运行"验证脚本
6. 点击"保存"

#### 8.2 编辑脚本

**代码编辑**：
- 使用Monaco编辑器编写代码
- 支持语法高亮和自动补全
- 支持代码折叠和格式化

**测试运行**：
- 点击"测试运行"按钮
- 查看输出结果
- 检查是否有错误

**依赖管理**：
- 系统自动识别import语句
- 自动安装缺失的依赖包
- 查看已安装的依赖列表

#### 8.3 使用预置脚本

系统预置了常用的数据生成脚本：

- `generate_phone_number`: 生成随机手机号
- `generate_id_card`: 生成随机身份证号
- `generate_email`: 生成随机邮箱
- `get_timestamp`: 获取当前时间戳
- `md5_encrypt`: MD5加密
- `generate_random_string`: 生成随机字符串
- `generate_random_number`: 生成随机数字

#### 8.4 脚本安全

- 脚本在沙箱环境中执行
- 执行超时限制：30秒
- 禁止访问文件系统和网络（除非明确允许）
- 所有脚本执行都有日志记录

### 9. 模板管理

#### 9.1 创建模板

1. 进入"模板管理"页面
2. 点击"新建模板"按钮
3. 选择模板类型（UI/接口/白盒）
4. 定义模板结构和字段
5. 设置默认值和验证规则
6. 保存模板

#### 9.2 使用模板

在用例生成时：

1. 点击"应用模板"按钮
2. 选择合适的模板
3. AI会按照模板格式生成用例
4. 模板字段会自动映射到用例

#### 9.3 模板示例

**UI测试模板**：
- 用例ID
- 用例标题
- 测试类型
- 优先级
- 前置条件
- 测试步骤（步骤1、步骤2...）
- 预期结果
- 测试数据
- 后置条件

**接口测试模板**：
- 用例ID
- 接口名称
- 请求方法
- 请求URL
- 请求头
- 请求体
- 断言配置
- 测试数据

### 10. Agent配置

#### 10.1 查看Agent配置

1. 进入"Agent配置"页面
2. 选择要查看的Agent
3. 查看当前配置信息

#### 10.2 修改Agent配置

**选择AI模型**：
- OpenAI: GPT-4、GPT-3.5-turbo
- Anthropic: Claude-3、Claude-2
- 本地模型: Ollama、LM Studio

**调整模型参数**：
- Temperature (0-2): 控制创造性，值越大越随机
- Max Tokens: 最大输出长度
- Top P: 采样概率

**编辑提示词**：
- 点击"编辑提示词"按钮
- 在编辑器中修改提示词模板
- 使用变量占位符（如{requirement_text}）
- 保存后立即生效

**关联知识库**：
- 勾选要关联的知识库
- 设置知识库权重
- 保存配置

#### 10.3 测试Agent

修改配置后，建议测试Agent：

1. 点击"测试Agent"按钮
2. 输入测试数据
3. 查看Agent输出结果
4. 确认配置是否符合预期

#### 10.4 恢复默认配置

如果配置出现问题：

1. 点击"恢复默认"按钮
2. 确认恢复操作
3. Agent配置会恢复到系统默认值

## 最佳实践

### 1. 需求输入建议

- **详细描述**: 需求描述越详细，生成的用例越准确
- **结构化**: 使用标题、列表等结构化格式
- **包含示例**: 提供具体的示例和数据
- **明确边界**: 说明功能的边界和限制

### 2. 场景选择建议

- **优先级排序**: 先选择P0和P1的高优先级场景
- **覆盖全面**: 确保正常、异常、边界场景都有覆盖
- **适度精简**: 删除重复和不必要的场景

### 3. 用例优化建议

- **多轮优化**: 不要期望一次生成完美用例，通过多轮对话逐步优化
- **具体明确**: 优化指令要具体明确，避免模糊表述
- **参考标准**: 参考SMART原则和公司测试规范

### 4. 知识库使用建议

- **及时更新**: 定期更新知识库内容
- **分类清晰**: 使用标签和分类管理文档
- **质量优先**: 上传高质量的历史用例和文档

### 5. 脚本使用建议

- **复用优先**: 优先使用预置脚本和已有脚本
- **测试充分**: 新脚本要充分测试后再使用
- **文档完善**: 为脚本添加清晰的注释和说明

## 常见问题

### Q1: 生成的用例不符合预期怎么办？

**A**: 可以通过以下方式改进：
1. 使用对话功能，明确告诉AI哪里不符合预期
2. 调整Agent配置，修改提示词或更换模型
3. 补充更详细的需求描述
4. 关联相关的知识库文档

### Q2: 如何提高用例生成的准确性？

**A**: 建议：
1. 提供详细、结构化的需求描述
2. 上传相关的知识库文档
3. 使用更强大的AI模型（如GPT-4）
4. 通过多轮对话逐步优化

### Q3: 生成的用例可以直接使用吗？

**A**: 建议不要直接使用，需要：
1. 仔细审查用例的准确性和完整性
2. 根据实际情况调整测试数据
3. 补充特定的业务规则和约束
4. 经过评审后再正式使用

### Q4: 如何管理大量的测试用例？

**A**: 建议：
1. 使用标签和分类管理用例
2. 定期清理过时的用例
3. 导出到专业的测试管理工具
4. 建立用例版本管理机制

### Q5: 系统支持哪些AI模型？

**A**: 目前支持：
- OpenAI: GPT-4、GPT-3.5-turbo、GPT-4-turbo
- Anthropic: Claude-3-opus、Claude-3-sonnet、Claude-2
- 本地模型: 通过Ollama或LM Studio部署的模型

### Q6: 如何保护敏感数据？

**A**: 系统提供以下保护措施：
1. 所有数据加密存储
2. 支持本地部署，数据不出内网
3. 可以配置数据脱敏规则
4. 定期备份和审计日志

### Q7: 生成用例需要多长时间？

**A**: 时间取决于：
- 需求复杂度：简单需求1-2分钟，复杂需求5-10分钟
- AI模型：GPT-4较慢但质量高，GPT-3.5较快
- 用例数量：场景越多，生成时间越长
- 网络状况：API调用受网络影响

### Q8: 如何自定义提示词？

**A**: 步骤：
1. 进入"Agent配置"页面
2. 选择要配置的Agent
3. 点击"编辑提示词"
4. 修改提示词模板
5. 使用变量占位符（如{requirement_text}）
6. 保存并测试

### Q9: 可以批量生成用例吗？

**A**: 可以：
1. 上传包含多个需求的文档
2. 系统会自动识别并分别处理
3. 或者使用API批量调用
4. 建议分批处理，避免超时

### Q10: 如何获取技术支持？

**A**: 支持渠道：
1. 查看系统文档和帮助中心
2. 提交Issue到GitHub仓库
3. 联系系统管理员
4. 加入用户交流群

---

如有其他问题，请参考[开发者文档](./开发者文档.md)或联系技术支持。
