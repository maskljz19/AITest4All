version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: ai-test-case-postgres
    environment:
      POSTGRES_DB: ai_test_case_generator
      POSTGRES_USER: ai_user
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-changeme}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ai_user -d ai_test_case_generator"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - ai-test-case-network
    restart: unless-stopped

  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: ai-test-case-redis
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
    networks:
      - ai-test-case-network
    restart: unless-stopped

  # Backend API
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: ai-test-case-backend
    environment:
      # Database
      DATABASE_URL: postgresql://ai_user:${POSTGRES_PASSWORD:-changeme}@postgres:5432/ai_test_case_generator
      REDIS_URL: redis://redis:6379/0
      
      # LLM API Keys (REQUIRED - set in .env file)
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY:-}
      
      # Security
      ENCRYPTION_KEY: ${ENCRYPTION_KEY:-}
      
      # LLM Configuration
      OPENAI_API_BASE: ${OPENAI_API_BASE:-https://api.openai.com/v1}
      ANTHROPIC_API_BASE: ${ANTHROPIC_API_BASE:-https://api.anthropic.com}
      DEFAULT_MODEL_PROVIDER: ${DEFAULT_MODEL_PROVIDER:-openai}
      DEFAULT_MODEL_NAME: ${DEFAULT_MODEL_NAME:-gpt-4}
      DEFAULT_TEMPERATURE: ${DEFAULT_TEMPERATURE:-0.7}
      DEFAULT_MAX_TOKENS: ${DEFAULT_MAX_TOKENS:-2000}
      
      # Application Settings
      APP_ENV: production
      APP_HOST: 0.0.0.0
      APP_PORT: 8000
      
      # Session
      SESSION_EXPIRE_HOURS: ${SESSION_EXPIRE_HOURS:-24}
      
      # File Upload
      MAX_UPLOAD_SIZE_MB: ${MAX_UPLOAD_SIZE_MB:-10}
      UPLOAD_DIR: /app/uploads
      
      # Script Execution
      SCRIPT_TIMEOUT_SECONDS: ${SCRIPT_TIMEOUT_SECONDS:-30}
      
      # Knowledge Base
      KNOWLEDGE_BASE_DIR: /app/knowledge_base
      
      # Agent Prompts
      AGENT_PROMPTS_DIR: /app/agent_prompts
      
      # Logging
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      LOG_FILE: /app/logs/app.log
      
      # CORS
      CORS_ORIGINS: ${CORS_ORIGINS:-http://localhost,http://localhost:80}
    volumes:
      - backend_uploads:/app/uploads
      - backend_knowledge:/app/knowledge_base
      - backend_logs:/app/logs
      - ./backend/agent_prompts:/app/agent_prompts:ro
    ports:
      - "8000:8000"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8000/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - ai-test-case-network
    restart: unless-stopped

  # Frontend
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: ai-test-case-frontend
    ports:
      - "3000:80"
    depends_on:
      - backend
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost/health || exit 1"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 20s
    networks:
      - ai-test-case-network
    restart: unless-stopped

  # Nginx Reverse Proxy (Optional - for production)
  nginx:
    image: nginx:alpine
    container_name: ai-test-case-nginx
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
      - nginx_logs:/var/log/nginx
    ports:
      - "80:80"
      - "443:443"
    depends_on:
      - backend
      - frontend
    networks:
      - ai-test-case-network
    restart: unless-stopped
    profiles:
      - production

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  backend_uploads:
    driver: local
  backend_knowledge:
    driver: local
  backend_logs:
    driver: local
  nginx_logs:
    driver: local

networks:
  ai-test-case-network:
    driver: bridge
